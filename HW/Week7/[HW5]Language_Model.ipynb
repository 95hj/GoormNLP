{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[HW5]Language_Model.ipynb","provenance":[{"file_id":"1kbrzV4kkX9pWFgDm6hMSDuDHcCMT8HF1","timestamp":1645424145562}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jR26RFkwXtvi"},"source":["# **[HW5] Language Model**\n","1. DataLoader\n","2. Model\n","3. Trainer\n","4. Generation\n","\n","이번 실습에서는 RNN기반의 Language Model를 구현해서 텍스트를 직접 생성해보는 실습을 진행해보겠습니다.\n","\n","- dataset: WikiText2 (https://github.com/pytorch/examples/tree/master/word_language_model/data/wikitext-2)\n","- model: LSTM\n"]},{"cell_type":"markdown","metadata":{"id":"crVJ36mMlaXP"},"source":["\n","\n","## Import packages"]},{"cell_type":"markdown","metadata":{"id":"zpvlE_XOWS33"},"source":["런타임의 유형을 변경해줍니다.\n","\n","상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n","\n","변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"cqVdEuPQzMAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645435195008,"user_tz":-540,"elapsed":6292,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}},"outputId":"ce93d6d9-78bc-46b9-ef6b-7895761b1b41"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torch.optim as optim\n","print(torch.__version__)\n","print(torch.cuda.is_available())"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["1.10.0+cu111\n","True\n"]}]},{"cell_type":"code","metadata":{"id":"2o3-HPdHLZma","executionInfo":{"status":"ok","timestamp":1645435195617,"user_tz":-540,"elapsed":612,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy as sp\n","import tqdm\n","import os\n","import random\n","import time\n","import datetime\n","\n","# for reproducibility\n","random.seed(1234)\n","np.random.seed(1234)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T1GnKJCB4T_Q"},"source":["# 1. DataLoader\n","\n","이전의 실습들에서 사용한것과 마찬가지로, PyTorch style의 dataloader를 먼저 만들어 두겠습니다."]},{"cell_type":"markdown","metadata":{"id":"wcNl0aWbS0OA"},"source":["### Dataset\n","\n","저희가 이번 실습에서 사용할 데이터셋은 Wikipedia에 있는 영문 글들을 가져온 WikiTree dataset입니다.\n","저희가 불러올 데이터는 가장 작은 WikiTree dataset에서 자주 사용되지 않는 단어나 영어가 아닌 단어들은 <unk>으로 이미 전처리가 되어있습니다."]},{"cell_type":"code","metadata":{"id":"CKf8zNuISiC2","executionInfo":{"status":"ok","timestamp":1645435196044,"user_tz":-540,"elapsed":430,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}}},"source":["import urllib\n","with urllib.request.urlopen('https://raw.githubusercontent.com/yunjey/pytorch-tutorial/master/tutorials/02-intermediate/language_model/data/train.txt') as f:\n","    data = f.readlines()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"jBLNOlRKSpOI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645435196044,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}},"outputId":"541789aa-d34e-4a99-9aa2-0956bfc90386"},"source":["print('num_sentence:',len(data))\n","data[100]"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["num_sentence: 42068\n"]},{"output_type":"execute_result","data":{"text/plain":["b\" plans that give advertisers discounts for maintaining or increasing ad spending have become permanent <unk> at the news <unk> and underscore the fierce competition between newsweek time warner inc. 's time magazine and <unk> b. <unk> 's u.s. news & world report \\n\""]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"OfLTv1EPbSwj","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1645435196967,"user_tz":-540,"elapsed":924,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}},"outputId":"9ade5042-a297-427a-86bb-1a0c745a898a"},"source":["seq_length_list = []\n","for line in data:\n","    seq_length_list.append(len(line.split()))\n","\n","counts, bins = np.histogram(seq_length_list, bins=20)\n","plt.hist(bins[:-1], bins, weights=counts)\n","plt.show()"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"4SdattmOcRwC"},"source":["데이터에 있는 문장 길이들의 histogram을 볼 때 대부분의 data의 문장 길이가 50에 미치지 못하기 때문에 \\\\\n","model에 집어넣을 최대 문장 길이를 50으로 세팅해두도록 하겠습니다."]},{"cell_type":"code","metadata":{"id":"g7MuFqsKcd4U","executionInfo":{"status":"ok","timestamp":1645435196968,"user_tz":-540,"elapsed":4,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}}},"source":["max_seq_len = 50"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IyMpsyX8TwYy"},"source":["### Build Dictionary\n","\n","먼저 text 데이터를 모델에 넣어주기 위해서는 text에 존재하는 단어들을 index로 변환해주어야 합니다.\n","\n","이를 위해서는 단어를 index로 변환해주는 word2idx dictionary와 다시 index를 단어로 변환해주는 idx2word dictionary를 만들어야 합니다.\n"]},{"cell_type":"code","metadata":{"id":"cZmyZhcpTvZz","executionInfo":{"status":"ok","timestamp":1645435197884,"user_tz":-540,"elapsed":919,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}}},"source":["def build_dictionary(data, max_seq_len):\n","    word2idx = {}\n","    idx2word = {}\n","    ## Build Dictionary\n","    word2idx['<pad>'] = 0\n","    word2idx['<unk>'] = 1\n","    idx2word[0] = '<pad>'\n","    idx2word[1] = '<unk>'\n","    idx = 2\n","    for line in data:\n","        words = line.decode('utf-8').split()\n","        words = words[:max_seq_len]        \n","        ### Build Dictionary to convert word to index and index to word\n","        ### YOUR CODE HERE (~ 5 lines)\n","        for word in words:\n","            if word not in word2idx:\n","                word2idx[word] = idx\n","                idx2word[idx] = word\n","                idx += 1\n","\n","    return word2idx, idx2word\n","\n","word2idx, idx2word = build_dictionary(data, max_seq_len)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPfV0OTc4Xdr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645435197884,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}},"outputId":"98d5e42e-a952-4155-babf-47427924d7e8"},"source":["if len(word2idx) == len(idx2word) == 10000:\n","    print(\"Test Passed!\")\n","else:\n","    raise AssertionError"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Passed!\n"]}]},{"cell_type":"markdown","metadata":{"id":"me_m8njoXHrv"},"source":["### Preprocessing\n","\n","이제 앞서 만든 dictionary를 이용해서 text로된 데이터셋을 index들로 변환시키겠습니다."]},{"cell_type":"code","metadata":{"id":"I6fuARgzXEDU","executionInfo":{"status":"ok","timestamp":1645435494683,"user_tz":-540,"elapsed":513,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}}},"source":["def preprocess(data, word2idx, idx2word, max_seq_len):\n","    tokens = []\n","    for line in data:\n","        words = line.decode('utf-8').split()\n","        words = words[:max_seq_len]\n","        ### Convert dataset with tokens\n","        ### For each line, append <pad> token to match the number of max_seq_len\n","        ### YOUR CODE HERE (~ 4 lines)\n","        for word in words:\n","            tokens.append(word2idx[word])\n","        tokens += [word2idx['<pad>']] * (max_seq_len - len(words))\n","      \n","    return tokens\n","\n","tokens = preprocess(data, word2idx, idx2word, max_seq_len)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"VjyvqMgbZnfP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645435496057,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}},"outputId":"081eff77-ad2b-40fa-d420-d251ff6618cb"},"source":["if len(tokens) == 2103400:\n","    print(\"Test Passed!\")\n","else:\n","    raise AssertionError"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Passed!\n"]}]},{"cell_type":"markdown","metadata":{"id":"jmQxX3BH-SAv"},"source":["이제 전처리된 Token들을 문장 단위의 배열로 변환시켜 두겠습니다."]},{"cell_type":"code","metadata":{"id":"knMvtp23-Jye","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645435525283,"user_tz":-540,"elapsed":423,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}},"outputId":"6766f8f6-ff8b-4283-dded-71ba36d2c182"},"source":["tokens = np.array(tokens).reshape(-1, max_seq_len)\n","print(tokens.shape)\n","tokens[100]"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["(42068, 50)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([745,  93, 746, 739, 747, 181, 748, 467, 749, 740, 750, 154, 751,\n","       752,   1, 160,  32, 753,   1,  48, 754,  32, 755, 756, 757, 728,\n","       555, 758,  99, 119, 555, 733,  48,   1, 759,   1, 119, 237, 753,\n","       230, 760, 347,   0,   0,   0,   0,   0,   0,   0,   0])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"pceBqmtTZ9g9"},"source":["### DataLoader\n","\n","이제 전처리된 dataset을 활용하여 PyTorch style의 dataset과 dataloader를 만들도록 하겠습니다.\n","\n","Token형태의 데이터를 PyTorch 스타일의 dataset으로 만들 때 주의할 점은, 추후 embedding matrix에서 indexing을 해주기 위해서 각 token이 LongTensor 형태로 정의되어야 한다는 점입니다."]},{"cell_type":"code","metadata":{"id":"1hAwhG1K9iBI","executionInfo":{"status":"ok","timestamp":1645435538939,"user_tz":-540,"elapsed":435,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}}},"source":["class LMDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokens):\n","        super(LMDataset, self).__init__()\n","        self.PAD = 0\n","        self.UNK = 1\n","        self.tokens = tokens\n","        self._getitem(2)\n","\n","    def _getitem(self, index):\n","        X = self.tokens[index]\n","        y = np.concatenate((X[1:], [self.PAD]))\n","\n","        X = torch.from_numpy(X).unsqueeze(0).long()\n","        y = torch.from_numpy(y).unsqueeze(0).long()\n","\n","        return X, y\n","\n","    def __getitem__(self, index):\n","        X = self.tokens[index]\n","        y = np.concatenate((X[1:], [self.PAD]))\n","\n","        X = torch.from_numpy(X).long()\n","        y = torch.from_numpy(y).long()\n","\n","        return X, y\n","\n","    def __len__(self):\n","        return len(self.tokens)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"BiLNqM6kAda1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645435542033,"user_tz":-540,"elapsed":403,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}},"outputId":"a4d2843c-dcad-40f0-d37d-11052ff6d01b"},"source":["batch_size = 64\n","dataset = LMDataset(tokens)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","print(len(dataset))\n","print(len(dataloader))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["42068\n","658\n"]}]},{"cell_type":"markdown","metadata":{"id":"b1nhBnqWxw4a"},"source":["# 2. Model\n","\n","이번 section에서는 Language Modeling을 위한 Recurrent Model을 직접 만들어보도록 하겠습니다.\n","\n","Standard한 Recurrent Neural Network (RNN) model은 vanishing gradient 문제에 취약하기 때문에, 이번 실습에서는 변형된 RNN구조인 LSTM model을 활용하도록 하겠습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"aOoNVt3MDOjl"},"source":["### LSTM"]},{"cell_type":"markdown","metadata":{"id":"9lycT_9vwaJN"},"source":["LSTM model의 전체적인 구조와 각 gate의 수식은 아래와 같습니다.\n","\n","![](https://drive.google.com/uc?export=view&id=1n93tpNW55Xl4GxZNcJcbUVRhuNCGH38h)"]},{"cell_type":"markdown","metadata":{"id":"S1h6nfvYwN8n"},"source":["![](https://drive.google.com/uc?export=view&id=1nH9U5iD9cO6OVVTbrx-LjypRvcWzbOCU)\n","\n","LSTM의 자세한 동작방식이 궁금하신 분은 아래의 블로그를 참조해주세요.\n","\n","https://colah.github.io/posts/2015-08-Understanding-LSTMs/"]},{"cell_type":"code","metadata":{"id":"YDNAysVqxxOk","executionInfo":{"status":"ok","timestamp":1645435675927,"user_tz":-540,"elapsed":395,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}}},"source":["class LSTMCell(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(LSTMCell, self).__init__()\n","        # input-gate\n","        self.Wi = nn.Linear(input_size + hidden_size, hidden_size)\n","        # forget-gate\n","        self.Wf = nn.Linear(input_size + hidden_size, hidden_size)\n","        # gate-gate\n","        self.Wg = nn.Linear(input_size + hidden_size, hidden_size)\n","        # output-gate\n","        self.Wo = nn.Linear(input_size + hidden_size, hidden_size)\n","\n","        # non-linearity\n","        self.sigmoid = nn.Sigmoid()\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, x, h_0, c_0):\n","        \"\"\"\n","        Inputs\n","            input (x): [batch_size, input_size]\n","            hidden_state (h_0): [batch_size, hidden_size]\n","            cell_state (c_0): [batch_size, hidden_size]\n","        Outputs\n","            next_hidden_state (h_1): [batch_size, hidden_size]\n","            next_cell_state (c_1): [batch_size, hidden_size]    \n","        \"\"\"\n","        h_1, c_1 = None, None\n","        input = torch.cat((x, h_0), 1) \n","        # Implement LSTM cell as noted above\n","        ### YOUR CODE HERE (~ 6 lines)\n","        i = self.sigmoid(self.Wi(input))\n","        f = self.sigmoid(self.Wf(input))\n","        g = self.tanh(self.Wg(input))\n","        o = self.sigmoid(self.Wo(input))\n","        c_1 = f * c_0 + i * g\n","        h_1 = o * self.tanh(c_1)\n","\n","        return h_1,c_1\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0Tff2VCJ56D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645435681032,"user_tz":-540,"elapsed":539,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}},"outputId":"defaad2b-3d17-4255-bb55-23d84be702fd"},"source":["def test_lstm():\n","    batch_size = 2\n","    input_size = 5\n","    hidden_size = 3\n","\n","    #torch.manual_seed(1234)\n","    lstm = LSTMCell(input_size ,hidden_size)\n","    def init_weights(m):\n","        if isinstance(m, nn.Linear):\n","            torch.nn.init.constant_(m.weight, 0.1)\n","            m.bias.data.fill_(0.01)\n","    lstm.apply(init_weights)\n","\n","    x = torch.ones(batch_size, input_size) \n","    hx = torch.zeros(batch_size, hidden_size) \n","    cx = torch.zeros(batch_size, hidden_size)\n","\n","    hx, cx = lstm(x, hx, cx)\n","    assert hx.detach().allclose(torch.tensor([[0.1784, 0.1784, 0.1784], \n","                                              [0.1784, 0.1784, 0.1784]]), atol=2e-1), \\\n","            f\"Output of the hidden state does not match.\"\n","    assert cx.detach().allclose(torch.tensor([[0.2936, 0.2936, 0.2936], \n","                                              [0.2936, 0.2936, 0.2936]]), atol=2e-1), \\\n","            f\"Output of the cell state does not match.\"\n","\n","    print(\"==LSTM cell test passed!==\")\n","\n","test_lstm()"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["==LSTM cell test passed!==\n"]}]},{"cell_type":"markdown","metadata":{"id":"0DxU-78B33dG"},"source":["## Language Model\n","\n","이제, 위에서 정의한 LSTM Cell을 활용해서 아래와 같은 Langauge Model을 만들어보도록 하겠습니다.\n","\n","\n","![](https://drive.google.com/uc?export=view&id=1nMAbL-g31nERM44dgohA3k9Vj_92hIh-)"]},{"cell_type":"code","metadata":{"id":"l0U2s0hux_n6","executionInfo":{"status":"ok","timestamp":1645435691365,"user_tz":-540,"elapsed":512,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}}},"source":["class LanguageModel(nn.Module):\n","    def __init__(self, input_size=64, hidden_size=64, vocab_size=10000):\n","        super(LanguageModel, self).__init__()\n","        \n","        self.input_layer = nn.Embedding(vocab_size, input_size)\n","        self.hidden_layer = LSTMCell(input_size, hidden_size)\n","        self.output_layer = nn.Linear(hidden_size, vocab_size)\n","\n","\n","    def forward(self, x, hx, cx, predict=False):\n","        \"\"\"\n","        Inputs\n","            input (x): [batch_size]\n","            hidden_state (h_0): [batch_size, hidden_size]\n","            cell_state (c_0): [batch_size, hidden_size]\n","            predict: whether to predict and sample the next word\n","        Outputs\n","            output (ox): [batch_size, hidden_size]\n","            next_hidden_state (h_1): [batch_size, hidden_size]\n","            next_cell_state (c_1): [batch_size, hidden_size]    \n","        \"\"\"\n","        x = self.input_layer(x)\n","        hx, cx = self.hidden_layer(x, hx, cx)\n","        ox = self.output_layer(hx)\n","\n","        if predict == True:\n","            probs = F.softmax(ox, dim=1)\n","            # torch distribution allows sampling operation\n","            # see https://pytorch.org/docs/stable/distributions.html\n","            dist = torch.distributions.Categorical(probs)\n","            ox = dist.sample()\n","\n","        return ox, hx, cx  "],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G-ZpuMhsbBS8"},"source":["# 3. Trainer\n","\n","자 이제 위에서 구현한 dataloader와 langauge model을 활용해서 모델의 학습을 진행해보도록 하겠습니다.\n"]},{"cell_type":"code","metadata":{"id":"y7TY7HmvbRlB","executionInfo":{"status":"ok","timestamp":1645435744680,"user_tz":-540,"elapsed":425,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}}},"source":["class Trainer():\n","    def __init__(self, \n","                 word2idx, \n","                 idx2word,\n","                 dataloader, \n","                 model, \n","                 criterion,\n","                 optimizer, \n","                 device):\n","        \"\"\"\n","        dataloader: dataloader\n","        model: langauge model\n","        criterion: loss function to evaluate the model (e.g., BCE Loss)\n","        optimizer: optimizer for model\n","        \"\"\"\n","        self.word2idx = word2idx\n","        self.idx2word = idx2word\n","        self.dataloader = dataloader\n","        self.model = model\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.device = device\n","        \n","    def train(self, epochs = 1):\n","        self.model.to(self.device)\n","        start_time = time.time()\n","        for epoch in range(epochs):\n","            losses = []\n","            for iter, (x_batch, y_batch) in tqdm.tqdm(enumerate(self.dataloader)):\n","                self.model.train()\n","                \n","                batch_size, max_seq_len = x_batch.shape\n","                x_batch = x_batch.to(self.device)\n","                y_batch = y_batch.to(self.device)\n","\n","                # initial hidden-states\n","                hx = torch.zeros(batch_size, hidden_size).to(self.device)\n","                cx = torch.zeros(batch_size, hidden_size).to(self.device)\n","\n","                # Implement LSTM operation\n","                ox_batch = []\n","                # Get output logits for each time sequence and append to the list, ox_batch\n","                # YOUR CODE HERE (~ 4 lines)\n","                for s_idx in range(max_seq_len):\n","                    x = x_batch[:, s_idx]\n","                    ox, hx, cx = self.model(x, hx, cx)\n","                    ox_batch.append(ox)\n","\n","                # outputs are ordered by the time sequence\n","                ox_batch = torch.cat(ox_batch).reshape(max_seq_len, batch_size, -1)\n","                ox_batch = ox_batch.permute(1,0,2).reshape(batch_size*max_seq_len, -1)\n","                y_batch = y_batch.reshape(-1)\n","\n","                self.model.zero_grad()\n","                loss = self.criterion(ox_batch, y_batch)\n","                loss.backward()\n","                self.optimizer.step()\n","                losses.append(loss.item())\n","\n","            end_time = time.time() - start_time\n","            end_time = str(datetime.timedelta(seconds=end_time))[:-7]\n","            print('Time [%s], Epoch [%d/%d], loss: %.4f'\n","                  % (end_time, epoch+1, epochs, np.mean(losses)))\n","            if epoch % 5 == 0:\n","                generated_sentences = self.test()\n","                print('[Generated Sentences]')\n","                for sentence in generated_sentences:\n","                    print(sentence)\n","            \n","    def test(self):\n","        # Test model to genereate the sentences\n","        self.model.eval()\n","        num_sentence = 5\n","        max_seq_len = 50\n","\n","        # initial hidden-states\n","        outs = []\n","        x = torch.randint(0, 10000, (num_sentence,)).to(self.device)\n","        hx = torch.zeros(num_sentence, hidden_size).to(self.device)\n","        cx = torch.zeros(num_sentence, hidden_size).to(self.device)\n","\n","        outs.append(x)\n","        with torch.no_grad():\n","            for s_idx in range(max_seq_len-1):\n","                x, hx, cx = self.model(x, hx, cx, predict=True)\n","                outs.append(x)\n","        outs = torch.cat(outs).reshape(max_seq_len, num_sentence)\n","        outs = outs.permute(1, 0)\n","        outs = outs.detach().cpu().numpy()\n","\n","        sentences = []\n","        for out in outs:\n","            sentence = []\n","            for token_idx in out:\n","                word = self.idx2word[token_idx]\n","                sentence.append(word)\n","            sentences.append(sentence)\n","       \n","        return sentences"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"fgEJv1vWqNkS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645437582623,"user_tz":-540,"elapsed":1835071,"user":{"displayName":"조현수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06575509224308139266"}},"outputId":"9ff957d6-09f9-4559-910c-0a9b230a1983"},"source":["lr = 1e-2\n","input_size = 128\n","hidden_size = 128\n","batch_size = 256\n","\n","dataset = LMDataset(tokens)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","model = LanguageModel(input_size=input_size, hidden_size=hidden_size)\n","# NOTE: you should use ignore_index to ignore the loss from predicting the <PAD> token\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","device = torch.device('cuda')\n","\n","trainer = Trainer(word2idx = word2idx,\n","                  idx2word = idx2word,\n","                  dataloader=dataloader, \n","                  model = model,\n","                  criterion=criterion,\n","                  optimizer = optimizer,\n","                  device=device)\n","\n","trainer.train(epochs=50)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:00:36], Epoch [1/50], loss: 6.1005\n","[Generated Sentences]\n","['preference', 'is', 'sagged', 'at', 'N', 'billion', 'yen', 'to', 'be', 'or', 'the', 'year-ago', 'period', 'at', 'N', 'N', 'point', 'to', 'close', 'against', '<unk>', 'the', 'lucrative', 'cease-fire', 'with', 'properties', 'to', '<unk>', 'the', 'plant', 'would', \"n't\", '<unk>', 'the', 'white', 'house', 'budget', 'teacher', 'said', 'stephen', 'british', 'executive', 'officer', 'of', 'black', 'california', 'thatcher', \"'s\", 'author', 'is']\n","['earnings', 'up', 'about', 'N', 'N', 'billion', 'a', 'movement', 'mass.', 'and', 'lower', 'international', 'work', 'bond', 'have', 'a', 'lot', 'as', 'the', 'food', 'african', 'program', 'trading', 'had', 'object', 'the', 'secondary', 'weekend', 'in', 'fashionable', 'majority', 'of', 't.', 'produced', 'equity', 'years', 'by', 'wolf', 'stocks', 'came', 'from', 'the', 'first', 'quarter', 'for', 'the', 'fierce', 'and', 'plastic', 'sustained']\n","['hunting', 'bounced', 'have', 'true', 'a', 'cooperatives', 'of', '$', 'N', 'billion', 'into', 'current', 'machines', 'in', 'donald', '<unk>', 'which', 'had', 'had', 'been', 'blocked', 'about', 'a', 'hostile', 'share', 'an', 'common', 'year', 'compared', 'with', '<unk>', 'nye', 'inc.', 'when', 'the', 'average', 'way', 'of', '<unk>', 'observed', 'and', 'the', 'socialist', 'account', 'barriers', 'of', 'your', 'inventory', 'program', 'and']\n","['new', 'security', 'sell', 'its', 'centennial', 'sale', 'of', '$', 'N', 'billion', 'but', 'sept.', 'N', 'N', 'sharp', 'highest', 'scattered', 'the', 'bank', 'such', 'some', 'income', 'as', 'delivery', 'this', 'year', 'these', 'high', 'up', '$', 'N', 'million', 'he', 'N', 'N', 'and', 'elsewhere', 'a', 'share', 'for', 'connaught', 'and', 'down', 'the', 'telecommunications', 'alleged', 'planes', 'and', 'quite', 'deferred']\n","['succeeded', 'sales', 'of', 'pit', 'as', 'u.s.', 'transactions', 'to', '$', 'N', 'a', 'share', 'due', 'N', 'million', 'a', 'share', 'in', '$', 'N', 'trillion', 'months', 'of', 'april', 'N', 'surveys', 'at', 'the', '$', 'N', 'million', 'last', 'year', 'were', 'off', 'the', 'early', 'sales', 'at', 'a', 'year', 'of', 'stock', 'prices', 'compared', 'to', '$', 'N', 'trillion', 'compared']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:01:13], Epoch [2/50], loss: 5.2211\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:01:50], Epoch [3/50], loss: 4.9075\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:02:27], Epoch [4/50], loss: 4.7044\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:03:03], Epoch [5/50], loss: 4.5492\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:03:40], Epoch [6/50], loss: 4.4231\n","[Generated Sentences]\n","['weakened', 'in', 'citizen', 'the', 'talks', 'might', \"n't\", 'mean', 'we', 'get', 'a', 'breakdown', 'that', 'money', 'should', 'the', 'team', 'far', '<unk>', 'their', 'hurdles', 'i', \"'m\", 'going', 'to', 'sue', 'concerns', 'or', 'areas', 'of', 'a', '<unk>', 'couple', 'with', 'racing', 'by', 'california', 'appropriations', 'committees', 'not', 'vision', 'of', 'their', 'fear', 'of', 'items', 'such', 'at', 'closely', 'held']\n","['with', 'other', 'difficult', 'circumstances', 'yesterday', 'that', 'in', 'minneapolis', 'he', 'has', 'put', 'the', 'main', 'irony', 'in', 'his', 'own', 'aoun', 'regulators', 'without', 'sending', 'a', '<unk>', '<unk>', 'over', 'the', 'economy', 'in', 'the', 'world', \"'s\", 'atmosphere', 'of', 'environmental', 'cases', 'to', 'hide', 'but', 'and', 'is', 'investment-grade', 'interest', 'rates', 'in', 'the', 'period', 'when', 'a', 'registered', 'in']\n","['refused', 'to', 'payment', 'of', '$', 'N', 'million', 'of', '$', 'N', 'million', 'a', 'year', 'but', 'he', 'wo', \"n't\", 'say', 'costly', 'credit', 'if', 'the', 'difficulties', 'market', \"'s\", 'impact', 'was', '$', 'N', 'million', 'or', 'N', 'cents', 'a', 'share', 'regular', 'treasury', 'fidelity', 'project', 'a', 'federal', 'antitrust', 'suit', 'he', '<unk>', 'and', 'a', 'group', 'headed', 'by']\n","['tasks', 'were', 'on', 'clothing', 'than', 'the', 'price', 'for', 'the', 'use', 'of', 'investors', \"'\", 'portfolios', 'as', 'an', 'insurance', 'company', 'but', 'rose', 'N', 'N', 'from', 'N', 'N', 'including', 'N', 'tentatively', 'priced', 'by', 'friday', 'when', 'the', '<unk>', 'is', 'more', '<unk>', 'of', 'the', 'building', \"'s\", 'second-largest', 'airline', 'and', 'thrift', 'chairman', 'stephen', 'wolf', 'proposed', 'to']\n","['fundamentally', 'exemption', 'of', 'billions', 'of', 'dollars', 'in', 'demand', 'for', 'letters', 'to', 'the', 'comptroller', 'and', '<unk>', 'products', 'are', 'below', 'the', 'company', 'as', '$', 'N', 'million', 'for', 'the', 'treasury', 'hotel', 'and', 'its', '<unk>', 'springs', '<unk>', 'in', 'los', 'angeles', 'investment', 'bank', 'trade', 'travel', 'life', 'co.', 'made', '$', 'N', 'billion', 'or', '$', 'N', 'to']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:04:17], Epoch [7/50], loss: 4.3159\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:04:54], Epoch [8/50], loss: 4.2229\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:05:30], Epoch [9/50], loss: 4.1433\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:06:07], Epoch [10/50], loss: 4.0740\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:06:44], Epoch [11/50], loss: 4.0102\n","[Generated Sentences]\n","['conasupo', 'facilities', 'they', 'are', 'currently', 'about', 'five', 'million', 'to', 'N', 'magazines', 'have', \"n't\", 'run', 'with', 'leveraged', 'buy-outs', 'were', 'slow', 'to', 'have', 'to', 'invest', 'in', 'treating', 'takeovers', 'in', 'the', 'industry', 'industry', 'with', 'a', 'plant', 'concern', 'have', 'led', 'the', 'biggest', 'insurer', 'is', 'subject', 'to', 'measure', 'murphy', 'brown', 'has', 'acquired', 'estimates', 'exceeding', 'a']\n","['locally', 'elected', 'governments', 'suppliers', 'a', 'friend', 'in', 'shanghai', 'states', 'conducting', '<unk>', 'in', 'the', 'west', 'usually', 'in', 'N', 'years', 'of', 'rising', '<unk>', 'a', '<unk>', 'industry', 'said', '<unk>', 'to', 'make', 'certain', 'of', '<unk>', '<unk>', 'scores', 'have', '<unk>', 'from', 'oklahoma', 'officials', 'that', 'trade', 'that', 'story', 'represents', 'a', 'resolution', 'that', 'he', 'will', 'explain', 'over']\n","['sciences', 'said', 'the', 'nation', \"'s\", 'large', 'department', 'store', 'giant', 'allianz', 'co.', 'a', 'unit', 'of', '<unk>', 'a', 'unit', 'of', 'dallas-based', 'chemical', '&', 'jacobson', 'who', 'chairman', 'said', 'the', 'company', 'said', 'ford', 'officials', 'also', 'say', 'it', 'will', 'be', 'in', 'active', 'trading', 'trading', 'yesterday', 'sterling', 'owed', 'to', '<unk>', 'over', 'the', 'next', 'year', 'while', 'stores']\n","['low-cost', 'monday', \"'s\", 'august', 'model', 'higher', 'was', 'potentially', 'small', 'yields', 'on', 'corporate', 'bonds', 'priced', 'at', 'N', 'one', 'point', 'it', \"'s\", 'lagging', '<unk>', '$', 'N', 'million', 'to', '<unk>', 'the', 'mci', 'of', 'the', 'division', 'a', 'drinking', 'restructuring', 'in', 'august', 'in', '<unk>', 'a', 'joint', 'venture', 'with', 'chief', 'executive', 'howard', '<unk>', 'a', 'subsidiary', 'and']\n","['behind', 'the', 'presidential', 'candidate', 'and', 'vowed', 'to', 'strip', 'columbia', \"'s\", 'shares', 'typically', 'closed', 'economies', 'to', 'N', 'years', 'and', 'portugal', 'at', 'another', 'steep', 'N', 'most', 'point', 'down', 'N', 'to', 'N', 'and', 'marks', '&', 'spencer', 'reported', 'N', 'N', 'in', 'august', 'at', 'N', 'from', 'an', 'asian', 'N', 'when', 'there', 'owned', 'no', 'a', 'buy']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:07:21], Epoch [12/50], loss: 3.9532\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:07:57], Epoch [13/50], loss: 3.9039\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:08:34], Epoch [14/50], loss: 3.8578\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:09:11], Epoch [15/50], loss: 3.8153\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:09:47], Epoch [16/50], loss: 3.7762\n","[Generated Sentences]\n","['hud', 'said', 'these', 'predicted', 'they', 'were', \"n't\", 'known', 'but', 'we', 'are', 'always', 'going', 'to', 'speak', 'out', 'detailed', 'sanctions', 'into', 'such', 'members', 'and', 'by', 'the', 'fbi', \"'s\", 'no.', 'N', '<unk>', 'rally', 'sunday', 'in', 'a', 'such', 'money', 'traders', 'will', 'now', 'open', 'the', 'offices', 'of', '<unk>', 'conn', 'on', 'serving', 'and', 'broken', '<unk>', 'with']\n","['sure', 'prices', 'extended', 'periods', 'despite', 'its', 'adrs', 'have', 'trimmed', 'below', 'changes', 'in', 'the', 'month', 'outstanding', 'has', 'weakened', 'in', 'the', 'affected', 'service', 'group', 'but', 'their', 'increases', 'subordinates', 'have', 'plagued', 'retail', 'reserves', 'by', '<unk>', 'last', 'week', 'on', 'taxes', 'because', 'by', 'computers', 'for', 'the', 'prestigious', 'rockefeller', 'university', 'of', 'the', 'maryland', 'maker', 'of', '<unk>']\n","['time', 'a', 'bipartisan', 'of', 'complaint', 'says', 'they', 'worry', 'that', 'presence', 'sought', 'is', 'at', 'least', 'one', 'in', 'part', 'now', 'after', 'after', 'it', 'was', 'bunny', '<unk>', 'said', 'they', 'would', 'be', 'a', 'matter', 'of', 'opposition', 'and', 'government', 'direct', 'market', 'share', 'of', 'the', 'ozone', 'layer', 'of', 'dismal', '<unk>', 'in', 'the', 'payment', 'of', 'the', 'galileo']\n","['banc', 'one', 'a', 'maker', 'of', 'independent', 'directors', 'to', 'focus', 'on', 'stock', 'futures', 'trading', 'at', '<unk>', 'and', '<unk>', 'types', 'of', 'cars', 'on', 'the', 'proposed', 'program', 'to', 'provide', 'australia', 'to', 'the', 'remainder', 'in', 'electronics', 'and', 'research', 'were', \"n't\", 'showing', 'that', 'is', 'part', 'of', 'the', 'country', \"'s\", 'sales', 'two', 'weeks', 'relating', 'to', 'assets']\n","['kean', 'hills', 'calif.', 'is', 'limited', 'to', 'the', 'loss', 'of', 'the', 'construction', 'software', 'program', 'in', 'N', 'to', 'fall', 'N', 'N', 'on', 'the', 'third', 'figures', 'none', '<unk>', 'gas', 'sales', 'of', 'about', 'N', 'cars', 'and', 'a', '<unk>', 'town', '<unk>', 'from', 'the', '<unk>', 'family', 'maintain', 'controlling', 'interest', 'reduce', 'consumer', 'prices', 'as', 'pension', 'financing', 'on']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:10:24], Epoch [17/50], loss: 3.7417\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:11:01], Epoch [18/50], loss: 3.7092\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:11:38], Epoch [19/50], loss: 3.6797\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:12:14], Epoch [20/50], loss: 3.6507\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:12:51], Epoch [21/50], loss: 3.6266\n","[Generated Sentences]\n","['towel', 'with', 'new', '<unk>', 'and', 'trust', 'said', 'but', 'it', \"'s\", '<unk>', 'about', 'property', 'and', 'rate', 'boost', 'to', 'be', 'available', 'to', 'buy', 'shares', 'of', 'N', 'N', 'stake', 'in', 'the', 'benchmark', '30-year', 'bond', 'that', 'was', 'an', 'easy', 'more', 'than', 'february', 'stock', 'prices', 'have', 'had', 'strong', 'five', 'years', 'mr.', '<unk>', 'said', 'it', 'once']\n","['barring', '<unk>', 'is', 'very', 'considerable', 'enough', 'to', 'some', 'estimate', 'that', 'need', 'to', 'avoid', 'closer', 'only', 'in', 'this', 'time', 'compared', 'with', 'delays', 'but', 'new', 'york', \"'s\", 'state-owned', 'sept.', 'N', 'slightly', 'remained', 'the', 'first', 'half', 'of', 'N', 'to', 'N', 'mr.', 'guber', 'and', 'recently', 'he', 'put', 'in', 'nature', 'to', 'survey', 'looked', 'to', 'load']\n","['deserves', 'except', 'for', '<unk>', 'dunn', 'has', 'offered', '$', 'N', 'asked', 'a', '<unk>', '<unk>', 'and', 'people', '<unk>', 'who', 'had', 'their', 'willingness', 'to', 'catch', 'some', 'sort', 'of', 'cash', 'and', 'technological', 'know-how', 'of', 'prudential', 'insurance', 'co', '<unk>', 'will', 'call', 'it', \"'s\", 'it', 'safe', 'fees', 'and', 'their', 'sense', 'by', 'entrepreneurs', 'on', 'the', 'securities', 'and']\n","['mountain-bike', 'users', 'inc.', 'an', '<unk>', 'company', 'in', 'new', 'york', 'the', 'union', 'the', 'south', 'division', 'is', 'a', 'paper', 'relationship', 'with', 'a', 'new', 'year', 'at', 'the', 'equivalent', 'of', '<unk>', \"'s\", 'economic', 'unity', '<unk>', 'of', 'investor', 'of', 'existing', 'arizona', 'real-estate', 'division', 'of', 'cos.', 'in', 'new', 'york', 'the', 'tribune', 'group', 'a', 'japanese', 'company', 'trader']\n","['members', 'on', 'the', 'futures', 'continued', 'strengthening', 'this', 'blow', 'for', 'its', '<unk>', '<unk>', 'rose', 'on', 'the', 'heels', 'of', 'the', 'nuclear', 'regulatory', 'commission', 'until', 'oct.', 'N', 'N', 'of', 'this', 'makes', 'packaging', 'prices', 'than', 'half', 'about', 'half', 'the', 'deaths', 'of', 'traders', 'to', 'the', 'corporations', \"'\", 'bid', 'will', 'continue', 'to', 'soften', 'the', 'collapse', 'of']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:13:28], Epoch [22/50], loss: 3.6026\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:14:04], Epoch [23/50], loss: 3.5797\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:14:41], Epoch [24/50], loss: 3.5592\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:15:18], Epoch [25/50], loss: 3.5402\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:15:54], Epoch [26/50], loss: 3.5238\n","[Generated Sentences]\n","['quantities', 'when', 'you', 'i', 'think', 'you', 'have', 'a', 'passion', 'he', 'recalls', 'but', 'president', 'bush', 'veto', 'power', 'after', 'payments', 'until', 'early', 'this', 'month', 'amid', 'the', 'studies', 'it', 'can', 'be', 'included', 'in', 'a', 'secret', 'position', 'over', 'declaring', 'by', 'lawmakers', 'by', 'diversifying', 'into', 'an', 'oregon', '<unk>', 'pot', 'trading', 'for', 'hong', 'kong', 'work', 'habits']\n","['security', 'ticket', 'splitting', 'along', 'to', 'invest', 'a', 'new', 'facility', 'and', 'used', 'to', 'cut', 'costs', 'and', 'boost', 'amounts', 'of', 'money', 'without', 'proceedings', 'differently', 'and', 'will', 'repeat', 'the', 'bellsouth', 'idea', 'too', 'soon', 'for', 'quick', 'construction', 'abroad', 'mostly', 'through', 'the', 'status', 'of', 'the', 'packaging', 'industry', 'may', 'not', 'be', 'in', '<unk>', 'and', 'moved', 'around']\n","['nomination', 'of', 'these', 'days', 'machinists', 'union', 'insurance', 'companies', 'were', 'not', 'as', 'a', 'member', 'of', 'the', 'document', 'and', 'ruled', 'out', 'of', 'the', 'freeway', 'in', 'and', 'chrysler', 'and', 'other', 'participants', 'because', 'it', 'added', 'is', 'being', 'squeezed', 'out', 'of', 'the', 'economy', 'from', 'the', 'takeover', 'front', 'six', 'senior', 'contracts', 'outstanding', 'from', 'the', 'executive', 'branch']\n","['performances', 'intensify', 'her', 'own', 'summer', 'people', 'agreed', 'to', 'become', 'smoothly', 'grounds', 'of', 'improvements', 'in', '<unk>', 'orders', 'with', 'gm', 'to', 'scrap', 'economic', 'trading', 'specifically', 'that', 'never', 'thought', 'it', 'is', 'seeking', 'to', 'realize', 'what', 'if', 'mr.', 'kasparov', 'found', 'not', 'enough', 'of', 'hard', 'need', 'to', 'realize', 'its', 'confidence', 'to', 'arrive', 'titles', 'by', 'the']\n","['concerned', 'i', 'already', 'has', 'fun', 'says', 'richard', 'jones', 'associates', 'inc.', 'in', 'atlanta', '<unk>', 'md.', 'securities', 'subcommittee', 'and', '<unk>', '&', '<unk>', 'inc', 'japan', '$', 'N', 'million', 'of', 'N', 'N', 'certificates', 'due', 'N', 'priced', 'to', 'yield', 'N', 'N', 'in', 'the', 'week', 'ended', 'september', 'N', 'from', 'N', 'with', 'a', 'third-quarter', 'loss', 'of', 'the']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:16:31], Epoch [27/50], loss: 3.5064\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:17:08], Epoch [28/50], loss: 3.4901\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:17:45], Epoch [29/50], loss: 3.4734\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:18:21], Epoch [30/50], loss: 3.4624\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:18:58], Epoch [31/50], loss: 3.4495\n","[Generated Sentences]\n","['investing', 'groups', 'watched', 'the', 'fundamentals', 'against', 'mrs.', '<unk>', 'says', 'most', 'survived', 'is', 'among', 'the', 'core', 'thrifts', 'and', 'will', 'remain', 'on', 'foreign', 'loans', 'to', 'less-developed', 'countries', 'from', '<unk>', 'industries', 'and', 'another', 'u.k.', 'image', 'advertising', 'firm', 'in', 'america', 'which', 'met', 'separately', 'announced', 'and', 'sold', 'to', 'the', 'swelling', 'balance', 'of', 'orders', 'for', 'use']\n","['contributed', 'shoulder', 'granting', 'disruptions', 'started', 'last', 'hotel', 'at', 'britain', 'of', 'dallas', 'whose', 'debt', 'households', 'established', 'in', 'ual', 'corp.', 'which', '<unk>', 'corporate', 'moves', 'are', 'eager', 'to', 'see', 'this', 'weather', '<unk>', 'later', 'than', 'the', '<unk>', '<unk>', 'of', 'the', 'defense', 'department', 'plans', 'according', 'to', 'the', 'transaction', 'said', 'they', 'agreed', 'along', 'with', 'that', 'government']\n","['convicted', 'mack', 'belgian', 'schools', 'especially', '<unk>', 'seem', 'to', 'be', '<unk>', 'so', 'much', 'more', '<unk>', 'to', 'mr.', 'honecker', '<unk>', 'of', 'this', 'episode', 'even', 'deep', 'convictions', 'in', 'previous', 'friends', 'who', 'had', 'discovered', '<unk>', 'in', 'his', 'profession', 'to', 'respond', 'by', 'the', '<unk>', '<unk>', 'article', 'a', '<unk>', '<unk>', 'of', '<unk>', 'and', 'held', 'by', 'what']\n","['withdrawals', 'definitive', 'figures', 'released', 'to', '$', 'N', 'million', 'since', 'N', 'the', 'soviets', 'rushed', 'to', 'extend', 'the', 'material', 'bids', 'for', 'some', 'of', 'marketing', 'and', '<unk>', 'although', 'they', 'own', 'under', 'the', 'board', \"'s\", 'decision', 'to', 'find', 'it', 'sir', 'alan', 'warns', 'that', 'congressional', 'legislation', 'threaten', 'in', 'mind', 'of', 'the', 'current', 'program', 'and', 'a']\n","['figuring', 'that', 'the', 'two', 'defendants', 'together', 'again', 'at', 'the', 'veto', '<unk>', 'sales', 'school', 'of', 'the', 'tokyo', 'stock', 'exchange', 'through', 'bear', 'stearns', '&', 'co.', 'and', 'noxell', 'corp.', 'a', 'state', 'department', 'spokesman', 'says', 'malcolm', 'grant', 'editor', 'of', 'numerous', 'new', 'york', 'and', 'market', 'zone', 'in', 'the', 'transportation', 'department', \"'s\", 'specialty', 'producers', 'and', 'lack']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:19:35], Epoch [32/50], loss: 3.4392\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:20:11], Epoch [33/50], loss: 3.4247\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:20:48], Epoch [34/50], loss: 3.4144\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:21:25], Epoch [35/50], loss: 3.4060\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:22:01], Epoch [36/50], loss: 3.3955\n","[Generated Sentences]\n","['acts', 'rebel', 'cutbacks', 'backed', 'crossland', 'properties', 'N', 'to', 'a', 'record', 'N', 'N', 'increase', 'in', 'revenue', 'in', 'the', 'venture', \"'s\", 'advertising', 'and', 'monetary', 'reserves', 'before', 'a', 'two-year', 'date', 'of', 'carbon', 'dioxide', 'as', 'a', 'previously', 'offer', 'exercised', 'for', 'the', 'fourth', 'quarter', 'while', 'remic', 'the', 'company', \"'s\", 'registered', 'immediate', 'outlook', 'at', 'all', 'what']\n","['unpopular', 'taxation', 'due', 'to', 'more', 'than', 'N', 'N', 'to', 'buy', 'N', 'boxes', 'and', '<unk>', 'agents', 'use', 'of', 'the', 'world', \"'s\", 'largest', 'no.', 'N', 'national', 'mortgage', 'association', 'last', 'week', 'miami-based', 'senior', 'notes', 'quebecor', 'of', 'swiss', 'debt', 'programs', 'it', '<unk>', 'all', 'of', 'their', 'rise', 'next', 'year', 'that', 'up', 'again', 'as', 'an', 'afternoon']\n","['team', 'returned', 'strip', '<unk>', 'the', 'assistant', 'university', 'of', 'the', 'workstation', '<unk>', 'cut', 'costs', 'for', 'the', 'north', 'american', 'and', 'goods', 'coors', 'of', 'chicago', '&', '<unk>', 'broadcasting', 'co.', 'and', 'public', 'operations', 'co.', 'golden', 'nugget', '<unk>', 'inc.', 'initial', 'public', 'offering', 'of', 'collateralized', 'mortgage', 'notes', 'shareholders', 'to', 'reopen', 'order', 'in', 'september', 'by', 'N', 'p.m.']\n","['second', 'he', 'says', 'would', 'grow', 'it', \"'s\", 'right', 'to', 'buy', 'gold', 'because', 'the', 'small', 'hybrid', 'market', 'in', 'the', 'financial', 'markets', 'clearing', 'with', 'large', 'oil', 'prices', \"'s\", 'pressure', 'below', 'expectations', 'with', 'N', 'bay-area', 'shares', 'outstanding', 'from', 'operating', 'tax', '<unk>', 'levels', 'to', 'the', '$', 'N', 'million', 'credit', 'lyonnais', 'which', 'gene', 'required', 'by']\n","['havoc', 'that', 'japanese', 'have', 'concluded', 'the', 'world', 'before', 'the', 'order', 'should', 'have', 'serious', 'something', 'she', 'says', 'the', 'representatives', 'will', 'draw', 'ground', 'particularly', 'complex', 'interest', 'trends', 'on', 'foreign', 'orders', 'and', 'to', '<unk>', 'to', 'the', '<unk>', 'more', 'upscale', 'play', 'and', 'then', 'would', 'need', 'the', 'decline', 'to', 'own', 'in', 'full', '<unk>', 'replacing', '<unk>']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:22:38], Epoch [37/50], loss: 3.3900\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:23:14], Epoch [38/50], loss: 3.3852\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:23:51], Epoch [39/50], loss: 3.3727\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:24:28], Epoch [40/50], loss: 3.3658\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:25:04], Epoch [41/50], loss: 3.3599\n","[Generated Sentences]\n","['sustained', 'altered', 'a', 'veteran', 'executive', 'who', 'funded', 'by', 'hurricane', 'hugo', 'and', 'the', 'greedy', 'u.s.', 'unit', 'might', 'be', 'completed', 'a', 'N', 'N', 'per-share', 'earnings', 'per', 'share', 'in', 'its', 'institutional', 'announcement', 'and', 'had', 'arranged', 'appointed', '<unk>', '&', 'dodge', '<unk>', 'ltd.', 'said', 'it', 'had', 'only', 'minor', 'damage', 'the', 'markets', 'estimated', 'profits', 'and', 'restructurings']\n","['disagreement', 'multimillion-dollar', 'disagreed', 'sweden', 'N', 'N', 'N', 'p.m.', 'est', 'on', 'pbs', 'thomas', 'hart', 'benton', 'cargo', 'henry', '&', '<unk>', 'inc', 'japan', '$', 'N', 'million', 'of', 'N', 'N', 'bonds', 'priced', 'at', 'N', 'to', 'yield', 'N', 'N', 'while', 'the', '<unk>', 'ratio', 'of', 'N', 'missiles', 'by', 'eliminating', 'data', 'on', 'electronic', 'products', 'manufacturer', 'through', 'california']\n","['capped', 'that', 'is', 'concentrated', 'the', 'environment', 'is', 'the', 'only', 'that', 'means', 'only', 'that', 'there', 'wo', \"n't\", 'contribute', 'to', 'a', '<unk>', 'sense', 'of', 'some', 'time', 'says', 'president', 'said', 'mr.', 'wohlstetter', 'said', 'he', 'expects', 'to', 'give', 'them', 'there', 'and', 'the', 'impact', 'of', 'the', 'notes', \"'\", 'plunge', 'of', 'vehicles', 'including', 'some', 'of', 'their']\n","['feels', 'covering', 'spot', 'freddie', 'mac', 'prices', 'of', 'the', 'city', \"'s\", 'board', 'was', 'caught', '<unk>', 'to', 'argue', 'that', 'which', 'assumes', 'a', 'lengthy', 'year', 'since', 'the', 'widget', 'agreement', 'according', 'to', 'the', 'announcement', 'said', 'edward', '<unk>', 'head', 'of', 'otc', 'trading', 'at', '$', 'N', 'million', 'on', 'oct.', 'N', 'million', 'common', 'shares', 'assuming', 'allianz', \"'s\"]\n","['construct', 'salinas', \"'s\", 'sept.', 'N', 'N', 'share', 'later', 'in', 'N', 'is', 'released', 'by', 'each', 'of', 'the', 'company', \"'s\", 'capacity', 'selling', 'out', 'to', 'their', 'business', 'applications', 'wo', \"n't\", 'be', 'unable', 'to', 'get', 'parental', 'consent', 'by', 'the', 'proposed', 'housing', 'unit', 'which', 'will', 'take', 'N', 'times', 'of', '<unk>', 'the', '$', 'N', 'billion', 'merger']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:25:41], Epoch [42/50], loss: 3.3508\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:26:18], Epoch [43/50], loss: 3.3461\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:26:54], Epoch [44/50], loss: 3.3410\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:27:31], Epoch [45/50], loss: 3.3342\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:28:08], Epoch [46/50], loss: 3.3303\n","[Generated Sentences]\n","['liquid', 'posts', 'soon', 'generally', 'does', \"n't\", 'expect', 'bellsouth', 'chairman', 'john', '<unk>', 'a', 'new', 'group', 'in', 'a', '<unk>', '<unk>', 'in', 'chicago', 'a', '<unk>', 'manufacturer', 'called', '<unk>', 'the', 'preamble', 'to', 'a', 'new', '<unk>', 'ca', 'at', 'the', 'same', 'one', 'might', 'select', 'their', 'conclusions', 'on', 'the', 'federal', 'trade', 'commission', 'in', 'the', 'new', 'zealand', 'and']\n","['investigating', 'jupiter', 'together', 'mary', 'farrell', 'lawrence', '<unk>', 'fazio', 'fleet', 'of', 'lawsuits', 'for', 'years', 'and', 'to', 'white', '<unk>', 'the', 'performance', 'of', 'the', '<unk>', 'and', 'in', '<unk>', 'n.y.', 'and', 'a', 'dozen', 'of', 'the', 'justice', 'department', 'of', 'the', 'president', \"'s\", '<unk>', 'drug', '<unk>', 'and', '<unk>', 'will', 'jolt', '<unk>', 'and', '<unk>', 'both', '<unk>', 'and']\n","['colombian', 'lawsuits', 'with', 'the', 'recent', 'crash', 'protection', 'from', '<unk>', '<unk>', \"'s\", 'most', 'innovative', '<unk>', 'investments', 'thrifts', 'over', 'computer', 'lows', 'dealers', \"'\", 'marketing', 'inc', 'by', 'noting', 'that', 'such', 'essential', 'products', 'company', 'earned', '$', 'N', 'million', 'or', 'N', 'cents', 'a', 'share', 'a', 'year', 'ago', 'in', '$', 'N', 'million', 'and', '<unk>', 'at', 'the']\n","['five-year', 'widow', 'talked', 'since', 'jan.', 'N', 'N', 'after', 'the', 'last', 'recession', 'had', 'sales', 'money', 'on', 'its', 'record', 'moving', 'off', 'a', 'lower', 'earnings', 'plus', 'leveraged', 'resulting', 'from', 'the', 'lowest', 'in', 'N', 'and', 'in', 'the', 'week', 'and', 'its', 'reluctance', 'as', 'numerous', 'electric', 'space', 'and', 'reduced', 'its', 'money', 'rolling', 'off', '$', 'N', 'million']\n","['struggled', 'to', 'set', 'ual', 'holder', 'approval', 'by', 'next', 'year', 'this', 'year', 'could', 'be', 'paid', '$', 'N', 'million', 'to', 'come', 'in', 'the', 'communication', 'or', '<unk>', 'of', 'its', 'editorial', 'quality', 'and', '<unk>', 'are', '<unk>', 'with', 'more', 'than', 'N', 'buying', 'and', '<unk>', 'europe', \"'s\", 'recently', 'announced', 'plans', 'even', 'ual', 'accepted', 'the', 'disappearance', 'of']\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:28:44], Epoch [47/50], loss: 3.3253\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:29:21], Epoch [48/50], loss: 3.3224\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Time [0:29:58], Epoch [49/50], loss: 3.3181\n"]},{"output_type":"stream","name":"stderr","text":["165it [00:36,  4.50it/s]"]},{"output_type":"stream","name":"stdout","text":["Time [0:30:34], Epoch [50/50], loss: 3.3143\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"nDhlrcENM4Dx"},"source":["생성된 텍스트의 퀄리티는 어떤가요? \n","\n","앞으로 딥러닝 강의가 끝나면 자연어처리 강좌에서 본격텍스트 처리에 적합한 전처리, 모델구조, 학습 trick들을 배우시게 될것입니다."]},{"cell_type":"markdown","metadata":{"id":"1Ua-_6W2a5Lt"},"source":["# References\n","\n","1. https://github.com/pytorch/examples/tree/master/word_language_model\n","2. https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model"]}]}